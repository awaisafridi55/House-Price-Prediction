{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ac81c-b6c0-403a-b627-99973864d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, StackingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import joblib\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load dataset\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['Price'] = data.target\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(df[['MedInc', 'HouseAge', 'AveRooms', 'AveOccup', 'Price']])\n",
    "plt.show()\n",
    "\n",
    "# Data Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X = df.drop(columns=['Price'])\n",
    "y = df['Price']\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train_poly, X_test_poly, _, _ = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training & Evaluation\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"ElasticNet Regression\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"Support Vector Regressor\": SVR(kernel='rbf', C=100, gamma=0.1),\n",
    "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"MLP Regressor\": MLPRegressor(hidden_layer_sizes=(64,64), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "    print(f\"{name} - MAE: {mae:.2f}, MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2 Score: {r2:.2f}\")\n",
    "\n",
    "# Deep Learning Model\n",
    "dnn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "dnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "dnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=1)\n",
    "\n",
    "dnn_pred = dnn_model.predict(X_test).flatten()\n",
    "dnn_r2 = r2_score(y_test, dnn_pred)\n",
    "print(f\"Deep Neural Network R2 Score: {dnn_r2:.2f}\")\n",
    "\n",
    "# Stacking Model\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)),\n",
    "    ('svr', SVR(kernel='rbf', C=100, gamma=0.1))\n",
    "]\n",
    "stacking_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
    "stacking_model.fit(X_train, y_train)\n",
    "stk_pred = stacking_model.predict(X_test)\n",
    "stk_r2 = r2_score(y_test, stk_pred)\n",
    "print(f\"Stacking Model R2 Score: {stk_r2:.2f}\")\n",
    "\n",
    "# Feature Importance for Random Forest\n",
    "rf_model = models[\"Random Forest\"]\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances, y=feature_names, palette='viridis')\n",
    "plt.title(\"Feature Importance in Random Forest Model\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP Explainability for Multiple Models\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_train)\n",
    "        shap.summary_plot(shap_values, X_train, feature_names=feature_names)\n",
    "    except:\n",
    "        print(f\"SHAP not supported for {name}\")\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "random_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='r2', n_iter=10)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters for Random Forest:\", random_search.best_params_)\n",
    "\n",
    "# Save best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['R2'])\n",
    "best_model = models[best_model_name]\n",
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "print(f\"Best Model: {best_model_name} with R2 Score: {results[best_model_name]['R2']:.2f}\")\n",
    "\n",
    "# Export results to CSV\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv(\"model_performance.csv\", index=True)\n",
    "\n",
    "# Load and test saved model\n",
    "loaded_model = joblib.load(\"best_model.pkl\")\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "loaded_r2 = r2_score(y_test, y_pred_loaded)\n",
    "print(f\"Loaded Model R2 Score: {loaded_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76e661-43e6-4752-8cfb-cf247e931878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8d6e5-5137-4eb9-9b20-e54b0012ce13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
